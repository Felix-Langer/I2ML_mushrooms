---
title: "Mushroom Classification"
author: "Andreas Kla√ü, Cornelia Gruber, Felix Langer, Viktoria Szabo"
date: "10.05.2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE,fig.align = 'center',out.width="100%",fig.cap="source: https://blog.goodeggs.com/blog/cooking-different-types-of-mushrooms"}
knitr::include_graphics("images/mushrooms1.jpg")
```


Collecting mushrooms recently gained popularity (if you believe Instagram influencers and mushroom picking blogs). Since mushrooms come in many different colors and shapes, their fit or unfit for human consumption is not necessarily obvious. Naturally, instead of asking your grandparents for advice a statistical analysis is the way to go to find out whether a mushroom is edible or poisonous given attributes concerning the look or smell of a mushroom.

### Mushroom attributes
Our main goal is to classify each mushroom into one of the two classes "edible" or "poisonous". For this task we can use various attributes of a mushroom's cap, gill or stalk or attributes like the odor, population or habitat of the mushroom. The cap shape for example can be either "bell", "conical", "convex", "flat", "knobbed" or "sunken" (see figure below). The dataset contains 8124 observations with 22 nominal features.

```{r, echo=FALSE,out.width="49%", out.height="20%",fig.cap="source: https://www.mushroomdiary.co.uk/mushroom-identification/",fig.show='hold',fig.align='center'}

knitr::include_graphics(c("images/parts-of-a-mushroom.gif","images/cap-shapes.gif"))

```

### Dataset Overview
Variable | Encoding
---------|---------
classes| edible=e,  poisonous=p
cap-shape| bell=b, conical=c, convex=x, flat=f,  knobbed=k, sunken=s  
cap-surface| fibrous=f, grooves=g, scaly=y, smooth=s  
cap-color| brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y  
bruises| bruises=t, no=f  
odor| almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s  
gill-attachment| attached=a, descending=d, free=f, notched=n  
gill-spacing| close=c, crowded=w, distant=d  
gill-size| broad=b, narrow=n  
gill-color| black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y  
stalk-shape| enlarging=e, tapering=t  
stalk-root| bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=?  
stalk-surface-above-ring| fibrous=f, scaly=y, silky=k, smooth=s  
stalk-surface-below-ring| fibrous=f, scaly=y, silky=k, smooth=s  
stalk-color-above-ring| brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y  
stalk-color-below-ring| brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y  
veil-type| partial=p, universal=u  
veil-color| brown=n, orange=o, white=w, yellow=y  
ring-number| none=n, one=o, two=t  
ring-type| cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z  
spore-print-color| black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y  
population| abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y  
habitat| grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d   



```{r,echo=FALSE, message=FALSE, warning=FALSE}
# load packages and data
library(tidyverse)
library(mlr3verse)
library(ranger) #random forests
library(gridExtra) #plotting 
library(precrec)
set.seed(123456)

# capture current ggplot theme and reset it at the end of the script:
original_ggplot_theme <- ggplot2::theme_get()
# set ggplot theme for this script:
ggplot2::theme_set(ggplot2::theme_bw())

#mushrooms for plotting with different factor lables, mushroom_data for modelling
mushrooms_data = read.csv("Data/mushrooms.csv") %>% 
  select( - veil.type)  # veil.type has only 1 level => omit variable
mushrooms = mushrooms_data
  
# setting var labels for plotting
mushrooms$class <- factor(mushrooms$class, labels = c("edible", "poisonous"))
mushrooms$odor <- factor(mushrooms$odor, labels = c("almond", "creosote", "foul", "anise", "musty", "none", "pungent", "spicy", "fishy"))
mushrooms$gill.color <- factor(mushrooms$gill.color, 
                         labels = c("buff", "red", "gray", "chocolate", 
                                     "black", "brown", "orange",
                                    "pink", "green", "purple", "white", "yellow"))
```


```{r}
#Overview of data
head(mushrooms_data)

summary(mushrooms_data)
```

In order to get a better feeling for our mushrooms let's do some plotting:   
Odor seems to be quite good indicator whether a mushroom is poisonous or edible.   
```{r, echo=FALSE}
p1 <- ggplot(mushrooms, aes(x= odor, fill = class)) +
  geom_bar() +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 45,  hjust = 1))+
  ggtitle("Distribution of class labels - odor")

p2 <- ggplot(mushrooms, aes(x = gill.color, fill = class)) +
  geom_bar()+
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 45,  hjust = 1))+
  ggtitle("Distribution of class labels - gill.color")

grid.arrange(p1, p2, ncol =2 )

```

### Mushroom Learning
#### Evaluation Framework

mlr3 is a machine learning (our in our case mushroom learning) framework offering a common ground for all necessary steps as defining a task, training a learner, predicting new data and resampling.    
A task in mlr3 contains the data as well as meta information such as the name of the target variable or if its a "classification" "regression" task.
```{r}
# Construct Classification Task 
task_mushrooms = TaskClassif$new(id = "mushrooms_data",
                               backend = mushrooms_data,
                               target = "class",
                               positive = "e") # "e" = edible
```


Additionally to building a machine learning model for predicting the classes it is crucial to obtain an unbiased generalization error for our estimates. Therefore we decided for a nested resampling strategy with a 5-fold CV in inner loop and a 10-fold CV in the outer loop. The number of folds was chosen in a way to balance the bias and variance of our estimate while still considering run time.   

```{r}
# Resampling Strategies 
# 5 fold cross validation for inner loop
resampling_inner_5CV = rsmp("cv", folds = 5L)
# 10 fold cross validation for outer loop
resampling_outer_10CV = rsmp("cv", folds = 10L)
```

While model tuning will be solely based on the AUC, printing
other measures is useful for assessing the performances for the more relevant error of falsely predicting a poisonous mushroom as edible.   
Since the range of values of the hyperparameters is quite limited we chose grid search for optimizing.
```{r}
# Performance Measures 
measures = list(
  msr("classif.auc",
      id = "AUC"),
  msr("classif.fpr",
      id = "False Positive Rate"), # false positive rate especially interesting
  # for our falsely edible (although actually poisonous) classification
  msr("classif.sensitivity",
      id = "Sensitivity"),
  msr("classif.specificity",
      id = "Specificity"),
  msr("classif.ce", 
      id = "MMCE")
)

# Choose optimization algorithm:
tuner_grid_search_knn = tnr("grid_search", resolution = 50)
tuner_grid_search_mtry = tnr("grid_search", resolution = 21)

# evaluate performance on AUC:
measures_tuning = msr("classif.auc", id = "AUC")
# Set when to terminate:
terminator_knn = term("evals", n_evals = 50)
# since almost all mtry values lead to very good results we evaluate 1 to 21 features as opposed to a termination criterion like stagnation
terminator_mtry = term("evals", n_evals = 21)  


```

#### Choosing algorithms
A relevant property of our dataset is that all features are nominal and thus multinomial distributed. Therefore linear and quadratic discriminant analyses (LDA and QDA) are due to the violated assumption of normally distributed features not possible.    
Following the performance of featureless, naive bayes, KNN, logistic regression, decision tree and random forest models will be compared.     

In the following part we define our inner loop of nested resampling. Only random forest (mtry) and KNN (k) have hyperparameters which will be tuned in a 5-fold-cv.

```{r}

# Autotune knn -----------------------------------------------------------------
# Define learner:
learner_knn = lrn("classif.kknn", predict_type = "prob")

# tune the chosen hyperparameter k with these boundaries:
param_k = ParamSet$new(
  list(
    ParamInt$new("k", lower = 1L, upper = 50)
  )
)

# Set up autotuner instance with the predefined setups
tuner_knn = AutoTuner$new(
  learner = learner_knn,
  resampling = resampling_inner_5CV,
  measures = measures_tuning, 
  tune_ps = param_k, 
  terminator = terminator_knn,
  tuner = tuner_grid_search_knn
)



# Autotune Random Forest ---------------------------------------------------------------------------
# Define learner:
learner_ranger = lrn("classif.ranger", predict_type = "prob", importance = "impurity")


# we will try all configurations: 1 to 21 features.
param_mtry = ParamSet$new(
  list(
    ParamInt$new("mtry", lower = 1L, upper = 21L)
  ) 
)

# Set up autotuner instance with the predefined setups
tuner_ranger = AutoTuner$new(
  learner = learner_ranger,
  resampling = resampling_inner_5CV,
  measures = measures_tuning,
  tune_ps = param_mtry, 
  terminator = terminator_mtry,
  tuner = tuner_grid_search_mtry
)


(learners = list(lrn("classif.featureless", predict_type = "prob"),
                lrn("classif.naive_bayes", predict_type = "prob"),
                lrn("classif.rpart", predict_type = "prob"),
                lrn("classif.log_reg", predict_type = "prob"),
                tuner_ranger,
                tuner_knn))
```


#### Results
Here the outer loop of nested resampling is done with a 10-fold-cv. 
```{r}
design = benchmark_grid(
  tasks = task_mushrooms,
  learners = learners,
  resamplings = resampling_outer_10CV
)



#lower the threshold to only print warnings:
lgr::get_logger("mlr3")$set_threshold("warn")

bmr = benchmark(design, store_models = TRUE)
# reset to default:
lgr::get_logger("mlr3")$set_threshold("info")

```
First of all we see that no errors or warnings occurred during resampling when printing the benchmark result print(bmr).

```{r}

print(bmr)
```

As expected a featureless model stays at a classification error of close to 0.5.


```{r}
autoplot(bmr)
autoplot(bmr, type = "roc")

(tab_learner_performance = bmr$aggregate(measures))
```

Logistic regression and random forest clearly lead to the best results when ranking the different models by their AUC. 

```{r}
learner_performance_ranked <- tab_learner_performance[,
                                                      .(learner_id,
                                                        rank_train = rank(-AUC),
                                                        rank_test = rank(MMCE))
                                                      ] %>% 
  arrange(rank_train) # sort in ascending order
learner_performance_ranked

```




### Final model
All steps so far answered the question which model with which hyperparameters yields good results with a now known generalization error. However to obtain the best possible model, training with all available data points is needed. We chose the random forest as final model for its interpretability and stability.  


```{r, results = 'hide'}
# Train tuner_ranger once again using the same specs as before
tuner_ranger$tuning_instance

# show only warnings:
lgr::get_logger("mlr3")$set_threshold("warn")
tuner_ranger$train(task_mushrooms)
# reset console outputs to default:
lgr::get_logger("mlr3")$set_threshold("info")

# AUC performance for parameter combinations:
tuner_ranger$tuning_instance$archive(unnest = "params")[,
                                                        c("mtry","AUC")] %>% 
  arrange(mtry)
# Pretty much every combination works perfectly

tuner_ranger$tuning_result # winning mtry is 3 although we could use
# 2-21 and achieve the same perfect performance

# use these parameters for our final winner model with winner specs:
learner_final = lrn("classif.ranger",predict_type = "prob")
learner_final$param_set$values = tuner_ranger$tuning_result$params

# Fit winner model to entire data set
learner_final$train(task_mushrooms)

```

With random forests we can asses the importance of each variable in the data. As suspected in the description part odor is clearly a good indicator for edibility of a mushroom.
```{r}
# construct filter to extract variable importance in previously set up winning learner
filter_ranger = flt("importance", learner = learner_final)
# rerun learner on entire data set and store variable importance results
filter_ranger$calculate(task_mushrooms)

feature_scores <- as.data.table(filter_ranger)

ggplot(data = feature_scores, 
       aes(x = reorder(feature, -score),
           y = score)) +
  geom_bar(stat = "identity") +
  ggtitle(label = "Mushroom Features - Variable Importance in Random Forest") +
  labs(x = "Features", y = "Variable Importance Score") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_continuous(breaks = pretty(1:feature_scores$score[1],10))

```


```{r, echo=FALSE}
# Reset ggplot theme -----------------------------------------------------------
theme_set(original_ggplot_theme)
```

